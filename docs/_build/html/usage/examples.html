

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Examples &mdash; parrot  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Module Documentation" href="../api.html" />
    <link rel="prev" title="parrot-predict" href="parrot-predict.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> parrot
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started with PARROT</a></li>
<li class="toctree-l1"><a class="reference internal" href="parrot-train.html">parrot-train</a></li>
<li class="toctree-l1"><a class="reference internal" href="parrot-optimize.html">parrot-optimize</a></li>
<li class="toctree-l1"><a class="reference internal" href="parrot-predict.html">parrot-predict</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parrot-train">parrot-train</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parrot-optimize">parrot-optimize</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parrot-predict">parrot-predict</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml_faqs.html">Machine Learning Resources:</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">parrot</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Examples</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/usage/examples.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<p>Below are a handful of examples outlining how PARROT can be used to train a BRNN on various machine learning tasks. Provided in the PARROT distribution on GitHub is a <strong>data</strong> folder which has 4 different example datasets corresponding to the possible combinations of data format (sequence-mapped values and residue-mapped values) and machine learning task (classification and regression). Details on these datasets can be found in the README within the <strong>data</strong> folder. This folder also contains an example list of sequences for <code class="docutils literal notranslate"><span class="pre">parrot-predict</span></code>, and other files that are used in these examples.</p>
<div class="section" id="parrot-train">
<h2>parrot-train<a class="headerlink" href="#parrot-train" title="Permalink to this headline">¶</a></h2>
<p><strong>Sequence classification:</strong>
In our first example, each of the 300 sequences in <em>seq_class_dataset.tsv</em> belongs to one of three classes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Frag0 WKHNPKHLRP <span class="m">0</span>
Frag1 DLFQDEDDAEEEDFMDDIWDPDS <span class="m">1</span>
Frag2 YHFAFTHMPALISQTSKYHYYSASMRG <span class="m">2</span>
Frag3 CNRNRNHKLKKFKHKKMGVPRKKRKHWK <span class="m">0</span>
...
</pre></div>
</div>
<p>Let’s train a network with <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> that can identify the inherent pattern (described in data/README.md). For starters, let’s try to train for 200 epochs on a network with 2 hidden layers, a hidden vector size of 5, a learning rate of 0.001 and a batch size of 32. Note that the paths for the dataset and output network may vary on different machines. Let’s also use the <code class="docutils literal notranslate"><span class="pre">-v</span></code> flag to get a sense of the training.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_class_dataset.tsv output_dir/network.pt --datatype sequence --classes <span class="m">3</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>Training has a stochastic component, so running this multiple times may yield slightly different results. The output should look something like:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>PARROT with user-specified parameters
-------------------------------------
Validation <span class="nb">set</span> loss per epoch:
Epoch <span class="m">0</span> Loss <span class="m">0</span>.0491
Epoch <span class="m">5</span> Loss <span class="m">0</span>.0486
Epoch <span class="m">10</span>        Loss <span class="m">0</span>.0482
...
Epoch <span class="m">190</span>       Loss <span class="m">0</span>.0063
Epoch <span class="m">195</span>       Loss <span class="m">0</span>.0063

Test Loss: <span class="m">0</span>.1932
</pre></div>
</div>
<p>In <strong>output_dir</strong>, there should also be two PNG files describing the training process and network performance.</p>
<a class="reference internal image-reference" href="../_images/train_test.png"><img alt="../_images/train_test.png" src="../_images/train_test.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="../_images/seq_CM.png"><img alt="../_images/seq_CM.png" src="../_images/seq_CM.png" style="width: 400px;" /></a>
<p>This gives us a general sense of how the network will perform on new data in the future. Overall the network performs well, and the only misclassifications are for sequences in class ‘2’.</p>
<p><strong>Sequence regression:</strong></p>
<p>Using PARROT on a machine learning regression task is very similar to classification. In <em>seq_regress_dataset.tsv</em>, instead of each sequence being assigned an integer class label, each sequence is represented by a real number.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Frag0 EHCWTYIFQMYRIDQTQRVKRGEKPIIYLEPMAR <span class="m">3</span>.8235294117647056
Frag1 SDAWVMKFLWDKCGDHFIQYQKPANRWEWVD <span class="m">3</span>.870967741935484
Frag2 IYPEQSPDNAWAW <span class="m">3</span>.076923076923077
...
</pre></div>
</div>
<p>The only difference in the <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> command in this regression case (other than the datafile path) is the <code class="docutils literal notranslate"><span class="pre">-c</span></code>/<code class="docutils literal notranslate"><span class="pre">--classes</span></code> argument. Since we are doing regression, we will put ‘1’ here. We could also change the network hyperparameters, but for now let’s just use the same as above. Notice that we are using a different output network name so as to not overwrite the previous network.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network2.pt --datatype sequence --classes <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>After this command, we see a similar output as before. In this case, in addition to <code class="docutils literal notranslate"><span class="pre">train_test.png</span></code> (this overwrites the previous image–if you are using the same output directory for lots of training, it may be wise to rename these files after each run) you will see a scatter plot detailing the predictions on the test set data.</p>
<a class="reference internal image-reference" href="../_images/seq_scatter.png"><img alt="../_images/seq_scatter.png" src="../_images/seq_scatter.png" style="width: 400px;" /></a>
<p>Not bad!</p>
<p><strong>Residue classification:</strong></p>
<p>Now let’s try a task where the objective is to classify each residue in a sequence. Unlike before, in <em>res_class_dataset.tsv</em> there are multiple values per sequence in the datafile.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Frag0 DEDGTEDDMATTK <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span>
Frag1 CGSAPSRFVKTCDPDEEDEDDEDE <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span>
Frag2 EWYEDDKPFPCPERVPHHKKGHRGGWRAKKNWKV <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">1</span> <span class="m">0</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">2</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">0</span>
...
</pre></div>
</div>
<p>Despite this major difference, the <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> command is similar to the above examples. The only difference will be the value we input after the <code class="docutils literal notranslate"><span class="pre">--datatype</span></code> flag. Before we put ‘sequence’, and here we will put ‘residues’. Just for fun, we will also switch up our number of layers (<code class="docutils literal notranslate"><span class="pre">-nl</span></code>) and hidden size (<code class="docutils literal notranslate"><span class="pre">-hs</span></code>) hyperparameters.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/res_class_dataset.tsv output_dir/network3.pt --datatype residues --classes <span class="m">3</span> -nl <span class="m">3</span> -hs <span class="m">8</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>This will save a confusion matrix ‘res_CM.png’ to the output directory. It’s nearly identical to the confusion matrix for sequence classification, although in this case it is for every single residue in all of the sequences in the test set.</p>
<a class="reference internal image-reference" href="../_images/res_CM.png"><img alt="../_images/res_CM.png" src="../_images/res_CM.png" style="width: 400px;" /></a>
<p><strong>Residue regression:</strong></p>
<p>The final kind of machine learning task that PARROT can handle is regression on every residue in a sequence. For this command <code class="docutils literal notranslate"><span class="pre">--datatype</span></code> should be set to ‘residues’ and <code class="docutils literal notranslate"><span class="pre">--classes</span></code> should be ‘1’. In this example I also changed the learning rate hyperparameter <code class="docutils literal notranslate"><span class="pre">-lr</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train prot-brnn/PARROT/data/res_regress_dataset.tsv saved_networks/example.pt --datatype residues --classes <span class="m">1</span> -nl <span class="m">3</span> -hs <span class="m">8</span> -lr <span class="m">0</span>.005 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>As in the other regression task, a residue regression task will produce a scatter plot that shows the network’s performance on the test set. Each combination of marker shape and color in this scatterplot belong to a single sequence, which may provide some insight on whether the network systematically mis-predicts all sequences, or if there are only a few specific sequences that are outliers.</p>
<a class="reference internal image-reference" href="../_images/res_scatter.png"><img alt="../_images/res_scatter.png" src="../_images/res_scatter.png" style="width: 400px;" /></a>
<p><strong>Other flags:</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">--stop</span></code>:
This flag determines the stop condition for network training. Currently, there are two options implemented: either ‘iter’ or ‘auto’. In all of the previous examples we used the default behavior, ‘iter’, which means that the number we specify for the <code class="docutils literal notranslate"><span class="pre">-e</span></code> flag will be the number of iterations that we train the network. Alternatively, using ‘auto’ means that training will stop automatically once performance on the validation set has plateaued for <code class="docutils literal notranslate"><span class="pre">-e</span></code> epochs. Thus, with ‘auto’ it is recommended to use a smaller number of epochs (5-15) for <code class="docutils literal notranslate"><span class="pre">-e</span></code> so training does not extend for a significantly long period of time.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">10</span> -b <span class="m">32</span> -vv --stop auto
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>PARROT with user-specified parameters
-------------------------------------
Train on:       cpu
Datatype:       sequence
ML Task:        regression
Learning rate:  <span class="m">0</span>.001000
Number of layers:       <span class="m">2</span>
Hidden vector size:     <span class="m">5</span>
Batch size:     <span class="m">32</span>

Validation <span class="nb">set</span> loss per epoch:

Epoch <span class="m">0</span> Loss <span class="m">0</span>.1779
Epoch <span class="m">1</span> Loss <span class="m">0</span>.1752
Epoch <span class="m">2</span> Loss <span class="m">0</span>.1727
...
Epoch <span class="m">98</span>        Loss <span class="m">0</span>.0456
Epoch <span class="m">99</span>        Loss <span class="m">0</span>.0456
Epoch <span class="m">100</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">101</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">102</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">103</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">104</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">105</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">106</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">107</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">108</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">109</span>       Loss <span class="m">0</span>.0456
Epoch <span class="m">110</span>       Loss <span class="m">0</span>.0455
Epoch <span class="m">111</span>       Loss <span class="m">0</span>.0455
Epoch <span class="m">112</span>       Loss <span class="m">0</span>.0455
</pre></div>
</div>
<p>Training stops here because performance has stopped improving. Worth mentioning: in some cases such as this dataset, ‘auto’ can actually get stuck in a local minimum well before the network is fully trained. Be mindful of this when using ‘auto’ stop condition.</p>
<p>You might also notice that in this example, the validation loss is listed for every single epoch instead of every 5. This is simply because multiple verbose <code class="docutils literal notranslate"><span class="pre">-v</span></code> flags are provided.</p>
<p><code class="docutils literal notranslate"><span class="pre">--set-fractions</span></code>:
This flag allows the user to set the proportions of data that will be a part of the training set, validation set, and test set. By default, the split is 70:15:15. This flag takes three input arguments, between 0 and 1, that must sum to 1.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v --set-fractions <span class="m">0</span>.5 <span class="m">0</span>.4 <span class="m">0</span>.1
</pre></div>
</div>
<p>Notice that the output graph from this command will have fewer datapoints because of the reduced test set. Most likely, the accuracy will be a little worse then the default proportions because the training set is also smaller.</p>
<p><code class="docutils literal notranslate"><span class="pre">--encode</span></code>:
This flag allows the user to specify how they want to numerically represent a sequence of amino acids. By default, PARROT uses one-hot encoding. Biophysical scale encoding is also hard-coded into PARROT, and can be used by providing ‘biophysics’ after this flag.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence --classes <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -e <span class="m">200</span> -b <span class="m">32</span> -v --encode biophysics
</pre></div>
</div>
<p>Alternatively, PARROT also allows the user to manually specify their own encoding scheme to be used, if they so wish. An example encoding file can be found in the <strong>data</strong> folder. In this case, provide the path to this encoding file following the flag.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence --classes <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -e <span class="m">200</span> -b <span class="m">32</span> -v --encode datasets/encoding.txt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">--split</span></code>:
This flag allows the user even greater control over the training set, validation set, and test set split of their input data. This flag requires an argument that is a path to a <cite>split_file</cite>, which specifically allocates sequences in <cite>datafile</cite> to the different datasets. An example <cite>split_file</cite> is provided in the /data folder for reference.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v --split datasets/split_file.tsv
</pre></div>
</div>
<p>This can especially be useful if you wish to perform k-fold cross-validation on your dataset, as you can prepare k different split_files that each specify a particular 1/kth of your dataset into the test set.</p>
<p><code class="docutils literal notranslate"><span class="pre">--exclude-seq-id</span></code>:
Include this flag if your <cite>datafile</cite> is formatted without sequence IDs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>EHCWTYIFQMYRIDQTQRVKRGEKPIIYLEPMAR <span class="m">3</span>.8235294117647056
SDAWVMKFLWDKCGDHFIQYQKPANRWEWVD <span class="m">3</span>.870967741935484
IYPEQSPDNAWAW <span class="m">3</span>.076923076923077
...
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v --exclude-seq-id
</pre></div>
</div>
</div>
<div class="section" id="parrot-optimize">
<h2>parrot-optimize<a class="headerlink" href="#parrot-optimize" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> will train a network like <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code>, however this command does not require the user to specify hyperparameters. Instead, it relies upon Bayesian Optimization to automatically select hyperparameters. Although Bayesian Optimization is much more efficient than grid search optimization, it still requires many iterations to converge upon the best hyperparameters. Additionally, this command relies upon 5-fold cross validation for each set of hyperparameters to achieve an accurate estimate of network performance. All together, this means that <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> can take over 400x longer to run than <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code>. It is strongly recommended to only run this command on a machine with a GPU.</p>
<p>Nonetheless, usage for <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> is remarkably similar to <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code>, since many of the flags are identical. As an example, let’s run the command on a residue regression dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-optimize datasets/res_regress_dataset.tsv output_dir/cv_example.pt --datatype residues --classes <span class="m">1</span> -e <span class="m">30</span> -b <span class="m">64</span> --max-iter <span class="m">20</span> -vv
</pre></div>
</div>
<p>Notice how we do not need to specify number of layers, hidden vector size, or learning rate as these are the parameters we are optimizing. Perhaps the most important consideration is the number of epochs. Running the optimization procedure with a large number of epochs is more likely to identify the best performing hyperparameters, however more epochs also means significantly longer run time. <strong>IMPORTANT: I used 30 epochs and 20 iterations here to speed up the example but it is HIGHLY recommended to &gt;150 epochs and the default iterations for normal usage.</strong> It is recommended to play around with your data using <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> with a few different parameters and visualizing ‘train_test.png’ in order to pick the number of epochs. Ideally, you should set the number of epochs to be around the point where validation accuracy tends to plateau during training.</p>
<p>Let’s break down what is output to console during the optimization procedure:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>PARROT with hyperparameter optimization
---------------------------------------
Train on:       cpu
Datatype:       residues
ML Task:        regression
Batch size:     <span class="m">64</span>
Number of epochs:       <span class="m">30</span>
Number of optimization iterations:      <span class="m">20</span>


Initial search results:
lr      nl      hs      output
<span class="m">0</span>.00001  <span class="m">5</span>      <span class="m">10</span>      <span class="m">3501</span>.8629
<span class="m">0</span>.00100  <span class="m">5</span>       <span class="m">5</span>      <span class="m">3093</span>.3104
<span class="m">0</span>.10000  <span class="m">8</span>      <span class="m">10</span>      <span class="m">3340</span>.8367
<span class="m">0</span>.01000 <span class="m">10</span>       <span class="m">5</span>      <span class="m">2349</span>.9827
<span class="m">0</span>.00100  <span class="m">3</span>      <span class="m">20</span>      <span class="m">979</span>.0830
Noise estimate: <span class="m">348</span>.4755793741326
</pre></div>
</div>
<p>(Note - Again, the point of this example is to illustrate what the output means, so don’t use these arguments when running <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> on your own data)</p>
<p>The first chunk of text details the network performance (for all 5 data folds) during the initial stage of hyperparameter optimization. This stage is used to gather an estimate of the noise (standard deviation across cross-val folds) for future optimization.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Primary optimization:
--------------------

Learning rate   <span class="p">|</span>   n_layers   <span class="p">|</span>   hidden vector size <span class="p">|</span>  avg CV <span class="nv">loss</span>
<span class="o">======================================================================</span>
  <span class="m">0</span>.024945      <span class="p">|</span>      <span class="m">1</span>       <span class="p">|</span>         <span class="m">20</span>           <span class="p">|</span>    <span class="m">62</span>.607
  <span class="m">1</span>.000000      <span class="p">|</span>      <span class="m">1</span>       <span class="p">|</span>         <span class="m">20</span>           <span class="p">|</span>    <span class="m">3353</span>.206
  <span class="m">0</span>.002081      <span class="p">|</span>      <span class="m">2</span>       <span class="p">|</span>         <span class="m">20</span>           <span class="p">|</span>    <span class="m">482</span>.241
  <span class="m">0</span>.007263      <span class="p">|</span>      <span class="m">1</span>       <span class="p">|</span>         <span class="m">20</span>           <span class="p">|</span>    <span class="m">105</span>.067
  <span class="m">0</span>.014636      <span class="p">|</span>      <span class="m">2</span>       <span class="p">|</span>         <span class="m">20</span>           <span class="p">|</span>    <span class="m">72</span>.831
  <span class="m">0</span>.012282      <span class="p">|</span>      <span class="m">1</span>       <span class="p">|</span>         <span class="m">19</span>           <span class="p">|</span>    <span class="m">82</span>.591
  <span class="m">0</span>.009382      <span class="p">|</span>      <span class="m">2</span>       <span class="p">|</span>         <span class="m">19</span>           <span class="p">|</span>    <span class="m">95</span>.740
  <span class="m">0</span>.001636      <span class="p">|</span>      <span class="m">1</span>       <span class="p">|</span>         <span class="m">17</span>           <span class="p">|</span>    <span class="m">1410</span>.856
  <span class="m">0</span>.007436      <span class="p">|</span>     <span class="m">10</span>       <span class="p">|</span>         <span class="m">20</span>           <span class="p">|</span>    <span class="m">2156</span>.534
  <span class="m">0</span>.026683      <span class="p">|</span>      <span class="m">4</span>       <span class="p">|</span>         <span class="m">18</span>           <span class="p">|</span>    <span class="m">72</span>.345
  <span class="m">0</span>.035740      <span class="p">|</span>      <span class="m">5</span>       <span class="p">|</span>         <span class="m">17</span>           <span class="p">|</span>    <span class="m">82</span>.965
  <span class="m">0</span>.187629      <span class="p">|</span>      <span class="m">5</span>       <span class="p">|</span>         <span class="m">18</span>           <span class="p">|</span>    <span class="m">3384</span>.214
  <span class="m">0</span>.009266      <span class="p">|</span>      <span class="m">4</span>       <span class="p">|</span>         <span class="m">17</span>           <span class="p">|</span>    <span class="m">176</span>.211
  <span class="m">0</span>.009710      <span class="p">|</span>      <span class="m">5</span>       <span class="p">|</span>         <span class="m">17</span>           <span class="p">|</span>    <span class="m">265</span>.559
  <span class="m">0</span>.010624      <span class="p">|</span>      <span class="m">3</span>       <span class="p">|</span>         <span class="m">18</span>           <span class="p">|</span>    <span class="m">90</span>.701
  <span class="m">0</span>.042102      <span class="p">|</span>      <span class="m">5</span>       <span class="p">|</span>         <span class="m">16</span>           <span class="p">|</span>    <span class="m">787</span>.841
  <span class="m">0</span>.005893      <span class="p">|</span>      <span class="m">4</span>       <span class="p">|</span>         <span class="m">18</span>           <span class="p">|</span>    <span class="m">238</span>.663
  <span class="m">0</span>.030018      <span class="p">|</span>      <span class="m">4</span>       <span class="p">|</span>         <span class="m">18</span>           <span class="p">|</span>    <span class="m">59</span>.166
  <span class="m">0</span>.057247      <span class="p">|</span>      <span class="m">3</span>       <span class="p">|</span>         <span class="m">18</span>           <span class="p">|</span>    <span class="m">248</span>.621
  <span class="m">1</span>.000000      <span class="p">|</span>      <span class="m">1</span>       <span class="p">|</span>          <span class="m">1</span>           <span class="p">|</span>    <span class="m">2693</span>.920

The optimal hyperparameters are:
<span class="nv">lr</span> <span class="o">=</span> <span class="m">0</span>.030018
<span class="nv">nl</span> <span class="o">=</span> <span class="m">4</span>
<span class="nv">hs</span> <span class="o">=</span> <span class="m">18</span>
</pre></div>
</div>
<p>This long block of text is the main process of optimization. The algorithm automatically selects the learning rate, number of layers and hidden vector size for each iteration. Finally, after the algorithm converges in 20 iterations (default: 75 iterations), the optimal hyperparameters are determined. These hyperparameters are also saved to a text file called ‘optimal_hyperparams.txt’ in the output directory. You might notice that the optimization procedure doesn’t appear to sample the entire hyperparameter space, but this is due to the fact that we specified to use fewer iterations than normally recommended.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Training with optimal hyperparams:
Epoch <span class="m">0</span> Loss <span class="m">3080</span>.3005
Epoch <span class="m">1</span> Loss <span class="m">3035</span>.0461
Epoch <span class="m">2</span> Loss <span class="m">2195</span>.9470
Epoch <span class="m">3</span> Loss <span class="m">1330</span>.2010
Epoch <span class="m">4</span> Loss <span class="m">1054</span>.5094
Epoch <span class="m">5</span> Loss <span class="m">583</span>.2585
Epoch <span class="m">6</span> Loss <span class="m">537</span>.2802
Epoch <span class="m">7</span> Loss <span class="m">462</span>.4870
Epoch <span class="m">8</span> Loss <span class="m">428</span>.7861
Epoch <span class="m">9</span> Loss <span class="m">329</span>.6138
Epoch <span class="m">10</span>        Loss <span class="m">343</span>.9399
.
.
.
Epoch <span class="m">48</span>        Loss <span class="m">12</span>.0531
Epoch <span class="m">49</span>        Loss <span class="m">13</span>.2082
Epoch <span class="m">50</span>        Loss <span class="m">15</span>.0165
Epoch <span class="m">51</span>        Loss <span class="m">17</span>.4953
Epoch <span class="m">52</span>        Loss <span class="m">21</span>.7618
Epoch <span class="m">53</span>        Loss <span class="m">21</span>.9459
Epoch <span class="m">54</span>        Loss <span class="m">18</span>.0915
Epoch <span class="m">55</span>        Loss <span class="m">13</span>.4374
Epoch <span class="m">56</span>        Loss <span class="m">8</span>.7067
Epoch <span class="m">57</span>        Loss <span class="m">7</span>.3803
Epoch <span class="m">58</span>        Loss <span class="m">9</span>.3223
Epoch <span class="m">59</span>        Loss <span class="m">9</span>.8348

Test Loss: <span class="m">0</span>.5138
</pre></div>
</div>
<p>Lastly, a network is trained on all the data using the optimal hyperparameters. Like in <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> two PNGs are saved to the output directory describing training and performance on the held-out test set.</p>
</div>
<div class="section" id="parrot-predict">
<h2>parrot-predict<a class="headerlink" href="#parrot-predict" title="Permalink to this headline">¶</a></h2>
<p>You can use a trained network from <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> or <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> to predict the values of new, unseen sequences (example provided in /data folder). The most important thing to keep in mind when using <code class="docutils literal notranslate"><span class="pre">parrot-predict</span></code> is that your <code class="docutils literal notranslate"><span class="pre">-nl</span></code> and <code class="docutils literal notranslate"><span class="pre">-hs</span></code> hyperparameters (and encoding scheme) must exactly match those used for network training, or else you will get an error.</p>
<p>seqfile.txt</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>a1 EADDGLYWQQN
b2 RRLKHEEDSTSTSTSTSTQ
c3 YYYGGAFAFAGRM
d4 GGIL
e5 GREPCCMLLYILILAAAQRDESSSSST
f6 PGDEADLGHRSLVWADD
</pre></div>
</div>
<p>Running <code class="docutils literal notranslate"><span class="pre">parrot-predict</span></code> on the example input file above:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-predict datasets/seqfile.txt output_dir/cv_example.pt output_dir/seq_predictions.txt --datatype residues --classes <span class="m">1</span> -nl <span class="m">1</span> -hs <span class="m">29</span>
</pre></div>
</div>
<p>Running this command produces an output file with predictions:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>a1 EADDGLYWQQN -1.220267 -1.7227852 -1.6810288 -2.4043236 -0.09417024 <span class="m">0</span>.64092124 <span class="m">0</span>.5456871 -1.8928833 -2.7887173 -3.6044078 -2.4574862
b2 RRLKHEEDSTSTSTSTSTQ -3.7224112 -1.8503121 -1.5983793 -1.2008493 -3.5577574 -3.4514222 -3.5511665 -2.6457114 -1.7057183 -0.78130686 -0.7216715 -0.7898313 -0.70238614 -0.7789676 -0.7124919 -0.7318907 -0.7426094 -1.5785892 -1.572853
c3 YYYGGAFAFAGRM -0.9441874 -1.3341192 -0.9653273 -0.69102514 <span class="m">0</span>.32323557 <span class="m">1</span>.4534209 <span class="m">2</span>.1537614 <span class="m">2</span>.429162 <span class="m">2</span>.2840738 <span class="m">1</span>.4165663 -0.881636 -1.2768524 -0.95433706
d4 GGIL -0.5195379 <span class="m">1</span>.1197864 <span class="m">2</span>.240749 <span class="m">2</span>.7807207
e5 GREPCCMLLYILILAAAQRDESSSSST -2.0686545 -2.7998338 -3.2005563 -0.89753973 <span class="m">1</span>.1320789 <span class="m">2</span>.3304148 <span class="m">2</span>.7493396 <span class="m">3</span>.2426906 <span class="m">2</span>.1906257 <span class="m">2</span>.5232615 <span class="m">2</span>.4606586 <span class="m">4</span>.522563 <span class="m">4</span>.0591545 <span class="m">3</span>.4521952 <span class="m">2</span>.415197 <span class="m">1</span>.8450507 <span class="m">0</span>.0069223046 -2.052992 -3.8073626 -3.8168678 -2.6170073 -1.7135364 -0.8026675 -0.7848917 -0.76005983 -0.73561 -0.6911867
f6 PGDEADLGHRSLVWADD -1.0060852 -1.9269344 -2.5225387 -1.6895776 -1.7939533 <span class="m">0</span>.6811078 <span class="m">0</span>.026133358 -0.08126199 -2.7815032 -2.8138366 -0.3407705 <span class="m">2</span>.483284 <span class="m">2</span>.4456654 <span class="m">1</span>.9606701 -0.705072 -1.9476694 -2.6707811
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../api.html" class="btn btn-neutral float-right" title="Module Documentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="parrot-predict.html" class="btn btn-neutral float-left" title="parrot-predict" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Holehouse Lab. Project structure based on the Computational Molecular Science Python Cookiecutter version 1.3

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>