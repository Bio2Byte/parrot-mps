

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Examples &mdash; parrot  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Module Documentation" href="../api.html" />
    <link rel="prev" title="parrot-predict" href="parrot-predict.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> parrot
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started with PARROT</a></li>
<li class="toctree-l1"><a class="reference internal" href="parrot-train.html">parrot-train</a></li>
<li class="toctree-l1"><a class="reference internal" href="parrot-optimize.html">parrot-optimize</a></li>
<li class="toctree-l1"><a class="reference internal" href="parrot-predict.html">parrot-predict</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parrot-train">parrot-train</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parrot-optimize">parrot-optimize</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parrot-predict">parrot-predict</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml_faqs.html">Machine Learning FAQs:</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">parrot</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Examples</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/usage/examples.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<p>Below are a handful of examples outlining how PARROT can be used to train a BRNN on various machine learning tasks. Provided in the PARROT distribution on GitHub is a <strong>data</strong> folder which has 4 different example datasets corresponding to the possible combinations of data format (sequence-mapped values and residue-mapped values) and machine learning task (classification and regression). Details on these datasets can be found in the README within the <strong>data</strong> folder. This folder also contains an example list of sequences for <code class="docutils literal notranslate"><span class="pre">parrot-predict</span></code>, and other files that are used in these examples.</p>
<div class="section" id="parrot-train">
<h2>parrot-train<a class="headerlink" href="#parrot-train" title="Permalink to this headline">¶</a></h2>
<p><strong>Sequence classification:</strong>
In our first example, each of the 300 sequences in <em>seq_class_dataset.tsv</em> belongs to one of three classes:</p>
<blockquote>
<div><div class="line-block">
<div class="line">Frag0 WKHNPKHLRP 0</div>
<div class="line">Frag1 DLFQDEDDAEEEDFMDDIWDPDS 1</div>
<div class="line">Frag2 YHFAFTHMPALISQTSKYHYYSASMRG 2</div>
<div class="line">Frag3 CNRNRNHKLKKFKHKKMGVPRKKRKHWK 0</div>
<div class="line">…</div>
</div>
</div></blockquote>
<p>Let’s train a network with <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> that can identify the inherent pattern (described in data/README.md). For starters, let’s try to train for 200 epochs on a network with 2 hidden layers, a hidden vector size of 5, a learning rate of 0.001 and a batch size of 32. Note that the paths for the dataset and output network may vary on different machines. Let’s also use the <code class="docutils literal notranslate"><span class="pre">-v</span></code> flag to get a sense of training.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_class_dataset.tsv output_dir/network.pt --datatype sequence --classes <span class="m">3</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>Training has a stochastic component, so running this multiple times may yield slightly different results. The output should look something like:</p>
<blockquote>
<div><div class="line-block">
<div class="line">Epoch 0       Loss 0.0491</div>
<div class="line">Epoch 5       Loss 0.0486</div>
<div class="line">Epoch 10      Loss 0.0482</div>
<div class="line">…</div>
<div class="line">Epoch 190     Loss 0.0063</div>
<div class="line">Epoch 195     Loss 0.0063</div>
<div class="line"><br /></div>
<div class="line">Test Loss: 0.1932</div>
</div>
</div></blockquote>
<p>In <strong>output_dir</strong>, there should also be two PNG files describing the training process and network performance.</p>
<a class="reference internal image-reference" href="../_images/train_test.png"><img alt="../_images/train_test.png" src="../_images/train_test.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="../_images/seq_CM.png"><img alt="../_images/seq_CM.png" src="../_images/seq_CM.png" style="width: 400px;" /></a>
<p>This gives us a general sense of how the network will perform on new data in the future. Overall the network performs well, and the only misclassifications are for sequences in class ‘2’.</p>
<p><strong>Sequence regression:</strong></p>
<p>Using PARROT on a machine learning regression task is very similar to classification. In <em>seq_regress_dataset.tsv</em>, instead of each sequence being assigned an integer class label, each sequence is represented by a real number.</p>
<blockquote>
<div><div class="line-block">
<div class="line">Frag0 EHCWTYIFQMYRIDQTQRVKRGEKPIIYLEPMAR 3.8235294117647056</div>
<div class="line">Frag1 SDAWVMKFLWDKCGDHFIQYQKPANRWEWVD 3.870967741935484</div>
<div class="line">Frag2 IYPEQSPDNAWAW 3.076923076923077</div>
<div class="line">…</div>
</div>
</div></blockquote>
<p>The only difference in the <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> command in this regression case (other than the datafile path) is the <code class="docutils literal notranslate"><span class="pre">-c</span></code>/<code class="docutils literal notranslate"><span class="pre">--classes</span></code> argument. Since we are doing regression, we will put ‘1’ here. We could also change the network hyperparameters, but for now let’s just use the same as above. Notice that we are using a different output network name so as to not overwrite the previous network.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network2.pt --datatype sequence --classes <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>After this command, we see a similar output as before. In this case, in addition to <code class="docutils literal notranslate"><span class="pre">train_test.png</span></code> (this overwrites the previous image–if you are using the same output directory for lots of training, it may be wise to rename these files after each run) you will see a scatter plot detailing the predictions on the test set data.</p>
<a class="reference internal image-reference" href="../_images/seq_scatter.png"><img alt="../_images/seq_scatter.png" src="../_images/seq_scatter.png" style="width: 400px;" /></a>
<p>Not bad!</p>
<p><strong>Residue classification:</strong></p>
<p>Now let’s try a task where the objective is to classify each residue in a sequence. Unlike before, in <em>res_class_dataset.tsv</em> there are multiple values per sequence in the datafile.</p>
<blockquote>
<div><div class="line-block">
<div class="line">Frag0 DEDGTEDDMATTK 1 1 1 1 1 1 1 1 1 1 1 1 1</div>
<div class="line">Frag1 CGSAPSRFVKTCDPDEEDEDDEDE 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1</div>
<div class="line">Frag2 EWYEDDKPFPCPERVPHHKKGHRGGWRAKKNWKV 1 1 1 1 1 1 1 0 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</div>
<div class="line">…</div>
</div>
</div></blockquote>
<p>Despite this major difference, the <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> command is similar to the above examples. The only difference will be the value we input after the <code class="docutils literal notranslate"><span class="pre">--datatype</span></code> flag. Before we put ‘sequence’, and here we will put ‘residues’. Just for fun, we will also switch up our number of layers (<code class="docutils literal notranslate"><span class="pre">-nl</span></code>) and hidden size (<code class="docutils literal notranslate"><span class="pre">-hs</span></code>) hyperparameters.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/res_class_dataset.tsv output_dir/network3.pt --datatype residues --classes <span class="m">3</span> -nl <span class="m">3</span> -hs <span class="m">8</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>This will save a confusion matrix ‘res_CM.png’ to the output directory. It’s nearly identical to the confusion matrix for sequence classification, although in this case it is for every single residue in all of the sequences in the test set.</p>
<a class="reference internal image-reference" href="../_images/res_CM.png"><img alt="../_images/res_CM.png" src="../_images/res_CM.png" style="width: 400px;" /></a>
<p><strong>Residue regression:</strong></p>
<p>The final kind of machine learning task that PARROT can handle is regression on every residue in a sequence. For this command <code class="docutils literal notranslate"><span class="pre">--datatype</span></code> should be set to ‘residues’ and <code class="docutils literal notranslate"><span class="pre">--classes</span></code> should be ‘1’. In this example I also changed the learning rate hyperparameter <code class="docutils literal notranslate"><span class="pre">-lr</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train prot-brnn/PARROT/data/res_regress_dataset.tsv saved_networks/example.pt --datatype residues --classes <span class="m">1</span> -nl <span class="m">3</span> -hs <span class="m">8</span> -lr <span class="m">0</span>.005 -e <span class="m">200</span> -b <span class="m">32</span> -v
</pre></div>
</div>
<p>As in the other regression task, a residue regression task will produce a scatter plot that shows the network’s performance on the test set. Each combination of marker shape and color in this scatterplot belong to a single sequence, which may provide some insight on whether the network systematically mis-predicts all sequences, or if there are only a few specific sequences that are outliers.</p>
<a class="reference internal image-reference" href="../_images/res_scatter.png"><img alt="../_images/res_scatter.png" src="../_images/res_scatter.png" style="width: 400px;" /></a>
<p><strong>Other flags:</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">--stop</span></code>:
This flag determines the stop condition for network training. Currently, there are two options implemented: either ‘iter’ or ‘auto’. In all of the previous examples we used the default behavior, ‘iter’, which means that the number we specify for the <code class="docutils literal notranslate"><span class="pre">-e</span></code> flag will be the number of iterations that we train the network. Alternatively, using ‘auto’ means that training will stop automatically once performance on the validation set has plateaued for <code class="docutils literal notranslate"><span class="pre">-e</span></code> epochs. Thus, with ‘auto’ it is recommended to use a smaller number of epochs (5-15) for <code class="docutils literal notranslate"><span class="pre">-e</span></code> so training does not extend for a significantly long period of time.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">10</span> -b <span class="m">32</span> -vv --stop auto
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">|</span> <span class="n">Epoch</span> <span class="mi">0</span>       <span class="n">Loss</span> <span class="mf">0.1779</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">1</span>       <span class="n">Loss</span> <span class="mf">0.1752</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">2</span>       <span class="n">Loss</span> <span class="mf">0.1727</span>
<span class="o">|</span> <span class="o">...</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">98</span>      <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">99</span>      <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">100</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">101</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">102</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">103</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">104</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">105</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">106</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">107</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">108</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">109</span>     <span class="n">Loss</span> <span class="mf">0.0456</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">110</span>     <span class="n">Loss</span> <span class="mf">0.0455</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">111</span>     <span class="n">Loss</span> <span class="mf">0.0455</span>
<span class="o">|</span> <span class="n">Epoch</span> <span class="mi">112</span>     <span class="n">Loss</span> <span class="mf">0.0455</span>
</pre></div>
</div>
<p>Training stops here because performance hasd stopped improving. Worth mentioning: in some cases such as this dataset, ‘auto’ can actually get stuck in a local minimum well before the network is fully trained. Be mindful of this when using ‘auto’ stop condition.</p>
<p><code class="docutils literal notranslate"><span class="pre">--setFractions</span></code>:
This flag allows the user to set the proportions of data that will be a part of the training set, validation set, and test set. By default, the split is 70:15:15. This flag takes three input arguments, between 0 and 1, that must sum to 1.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v --setFractions <span class="m">0</span>.5 <span class="m">0</span>.4 <span class="m">0</span>.1
</pre></div>
</div>
<p>Notice that the output graph from this command will have fewer datapoints because of the reduced test set. Most likely, the accuracy will be a little worse then the default proportions because the training set is also smaller.</p>
<p><code class="docutils literal notranslate"><span class="pre">--encode</span></code>:
This flag allows the user to specify how they want to numerically represent a sequence of amino acids. By default, PARROT uses one-hot encoding. Biophysical scale encoding is also hard-coded into PARROT, and can be used by providing ‘biophysics’ after this flag.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence --classes <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -e <span class="m">200</span> -b <span class="m">32</span> -v --encode biophysics
</pre></div>
</div>
<p>Alternatively, PARROT also allows the user to manually specify their own encoding scheme to be used, if they so wish. An example encoding file can be found in the <strong>data</strong> folder. In this case, provide the path to this encoding file following the flag.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence --classes <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -e <span class="m">200</span> -b <span class="m">32</span> -v --encode datasets/encoding.txt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">--split</span></code>:
This flag allows the user even greater control over the training set, validation set, and test set split of their input data. This flag requires an argument that is a path to a <cite>split_file</cite>, which specifically allocates sequences in <cite>datafile</cite> to the different datasets. An example <cite>split_file</cite> is provided in the /data folder for reference.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v --split datasets/split_file.tsv
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">--excludeSeqID</span></code>:
Include this flag if your <cite>datafile</cite> is formatted without sequence IDs:</p>
<blockquote>
<div><div class="line-block">
<div class="line">EHCWTYIFQMYRIDQTQRVKRGEKPIIYLEPMAR 3.8235294117647056</div>
<div class="line">SDAWVMKFLWDKCGDHFIQYQKPANRWEWVD 3.870967741935484</div>
<div class="line">IYPEQSPDNAWAW 3.076923076923077</div>
<div class="line">…</div>
</div>
</div></blockquote>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-train datasets/seq_regress_dataset.tsv output_dir/network.pt --datatype sequence -c <span class="m">1</span> -nl <span class="m">2</span> -hs <span class="m">5</span> -lr <span class="m">0</span>.001 -e <span class="m">200</span> -b <span class="m">32</span> -v --excludeSeqID
</pre></div>
</div>
</div>
<div class="section" id="parrot-optimize">
<h2>parrot-optimize<a class="headerlink" href="#parrot-optimize" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> will train a network like <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code>, however this command does not require the user to specify hyperparameters. Instead, it relies upon Bayesian Optimization to automatically select hyperparameters. Although Bayesian Optimization is much more efficient than grid search optimization, it still requires many iterations to converge upon the best hyperparameters. Additionally, this command relies upon 5-fold cross validation for each set of hyperparameters to achieve an accurate estimate of network performance. All together, this means that <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> can take over 400x longer to run than <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code>. It is strongly recommended to only run this command on a machine with a GPU.</p>
<p>Nonetheless, usage for <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> is remarkably similar to <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code>, since many of the flags are identical. As an example, let’s run the command on a residue regression dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-optimize datasets/res_regress_dataset.tsv output_dir/cv_example.pt --datatype residues --classes <span class="m">1</span> -e <span class="m">200</span> -b <span class="m">32</span> -vv
</pre></div>
</div>
<p>Notice how we do not need to specify number of layers, hidden vector size, or learning rate as these are the parameters we are optimizing. Perhaps the most important consideration is the number of epochs. Running the optimization procedure with a large number of epochs is more likely to identify the best performing hyperparameters, however more epochs also means significantly longer run time. It is recommended to play around with your data using <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> with a few different parameters and visualizing ‘train_test.png’. Ideally, you should set the number of epochs to be around the point where validation accuracy tends to plateau during training.</p>
<p>Let’s break down what is output to console during the optimization procedure:</p>
<blockquote>
<div><div class="line-block">
<div class="line">[1/5] Loss: 75.247434</div>
<div class="line">[2/5] Loss: 75.689319</div>
<div class="line">[3/5] Loss: 66.811298</div>
<div class="line">[4/5] Loss: 72.030063</div>
<div class="line">…</div>
<div class="line">[3/5] Loss: 1.476518</div>
<div class="line">[4/5] Loss: 1.395311</div>
<div class="line">[5/5] Loss: 1.380726</div>
<div class="line"><br /></div>
<div class="line">Initial search results:</div>
<div class="line">lr            nl      hs      output</div>
<div class="line">0.00001        5      10      73.2288</div>
<div class="line">0.00100        5       5      8.7716</div>
<div class="line">1.00000        8      20      66.9336</div>
<div class="line">0.00100       15       5      52.8299</div>
<div class="line">0.00100        3      30      1.4568</div>
<div class="line">Noise estimate: 3.285178370588926</div>
</div>
</div></blockquote>
<p>The first chunk of text details the network performance (for all 5 data folds) during the initial stage of hyperparameter optimization. This stage is used to gather an estimate of the noise (standard deviation across cross-val folds) for future optimization.</p>
<blockquote>
<div><div class="line-block">
<div class="line">Primary optimization:</div>
<div class="line">——————–</div>
<div class="line"><br /></div>
<div class="line">Learning rate   |   n_layers   |   hidden vector size</div>
<div class="line">=====================================================</div>
<div class="line-block">
<div class="line">0.000630     |      3       |         30</div>
</div>
<div class="line">[1/5] Loss: 1.881410</div>
<div class="line">[2/5] Loss: 2.010539</div>
<div class="line">[3/5] Loss: 1.651101</div>
<div class="line">[4/5] Loss: 1.631336</div>
<div class="line">[5/5] Loss: 3.060484</div>
<div class="line">…</div>
<div class="line"><br /></div>
<div class="line">The optimal hyperparameters are:</div>
<div class="line">lr = 0.004901</div>
<div class="line">nl = 1</div>
<div class="line">hs = 29</div>
</div>
</div></blockquote>
<p>This long block of text is the main process of optimization. The algorithm automatically selects the learning rate, number of layers and hidden vector size for each iteration. Finally, after the algorithm converges (max 75 iterations), the optimal hyperparameters are determined. These hyperparameters are also saved to a text file called ‘optimal_hyperparams.txt’ in the output directory.</p>
<blockquote>
<div><div class="line-block">
<div class="line">Training with optimal hyperparams:</div>
<div class="line">Epoch 0       Loss 56.9641</div>
<div class="line">…</div>
<div class="line"><br /></div>
<div class="line">Test Loss: 0.7732</div>
</div>
</div></blockquote>
<p>Lastly, a network is trained on all the data using the optimal hyperparameters. Like in <code class="docutils literal notranslate"><span class="pre">parrot-train</span></code> two PNGs are saved to the output directory describing training and performance on the held-out test set.</p>
</div>
<div class="section" id="parrot-predict">
<h2>parrot-predict<a class="headerlink" href="#parrot-predict" title="Permalink to this headline">¶</a></h2>
<p>Use the trained network from optimize and predict on an list of sequences (example provided in /data folder). In this case we will make residue regression prediction using the network trained from <code class="docutils literal notranslate"><span class="pre">parrot-optimize</span></code> above. The most important thing to keep in mind when using <code class="docutils literal notranslate"><span class="pre">parrot-predict</span></code> is that your <code class="docutils literal notranslate"><span class="pre">-nl</span></code> and <code class="docutils literal notranslate"><span class="pre">-hs</span></code> hyperparameters (and encoding scheme) must exactly match those used for network training, or else you will get an error.</p>
<p>Using the example input file:</p>
<blockquote>
<div><div class="line-block">
<div class="line">a1 EADDGLYWQQN</div>
<div class="line">b2 RRLKHEEDSTSTSTSTSTQ</div>
<div class="line">c3 YYYGGAFAFAGRM</div>
<div class="line">d4 GGIL</div>
<div class="line">e5 GREPCCMLLYILILAAAQRDESSSSST</div>
<div class="line">f6 PGDEADLGHRSLVWADD</div>
</div>
</div></blockquote>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>parrot-predict datasets/seqfile.txt output_dir/cv_example.pt output_dir/seq_predictions.txt --datatype residues --classes <span class="m">1</span> -nl <span class="m">1</span> -hs <span class="m">29</span>
</pre></div>
</div>
<p>Running this command produces an output file with predictions:</p>
<blockquote>
<div><div class="line-block">
<div class="line">a1 EADDGLYWQQN -1.220267 -1.7227852 -1.6810288 -2.4043236 -0.09417024 0.64092124 0.5456871 -1.8928833 -2.7887173 -3.6044078 -2.4574862</div>
<div class="line">b2 RRLKHEEDSTSTSTSTSTQ -3.7224112 -1.8503121 -1.5983793 -1.2008493 -3.5577574 -3.4514222 -3.5511665 -2.6457114 -1.7057183 -0.78130686 -0.7216715 -0.7898313 -0.70238614 -0.7789676 -0.7124919 -0.7318907 -0.7426094 -1.5785892 -1.572853</div>
<div class="line">c3 YYYGGAFAFAGRM -0.9441874 -1.3341192 -0.9653273 -0.69102514 0.32323557 1.4534209 2.1537614 2.429162 2.2840738 1.4165663 -0.881636 -1.2768524 -0.95433706</div>
<div class="line">d4 GGIL -0.5195379 1.1197864 2.240749 2.7807207</div>
<div class="line">e5 GREPCCMLLYILILAAAQRDESSSSST -2.0686545 -2.7998338 -3.2005563 -0.89753973 1.1320789 2.3304148 2.7493396 3.2426906 2.1906257 2.5232615 2.4606586 4.522563 4.0591545 3.4521952 2.415197 1.8450507 0.0069223046 -2.052992 -3.8073626 -3.8168678 -2.6170073 -1.7135364 -0.8026675 -0.7848917 -0.76005983 -0.73561 -0.6911867</div>
<div class="line">f6 PGDEADLGHRSLVWADD -1.0060852 -1.9269344 -2.5225387 -1.6895776 -1.7939533 0.6811078 0.026133358 -0.08126199 -2.7815032 -2.8138366 -0.3407705 2.483284 2.4456654 1.9606701 -0.705072 -1.9476694 -2.6707811</div>
</div>
</div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../api.html" class="btn btn-neutral float-right" title="Module Documentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="parrot-predict.html" class="btn btn-neutral float-left" title="parrot-predict" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Holehouse Lab. Project structure based on the Computational Molecular Science Python Cookiecutter version 1.3

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>